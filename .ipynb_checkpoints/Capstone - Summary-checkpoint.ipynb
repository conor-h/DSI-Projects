{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the project was to explore different methodologies to build and implement a simple recommender system that would recommend movies based on information from the MovieLens dataset. This dataset was updated with data scraped from the corresponding IMDb pages for each movie. The recommendation engine was based on the cleaned dataset and the accuracy of the predicted ratings was evaluted.\n",
    "\n",
    "\n",
    "Recommendation engines are a major part of everyday life with personalised recommendations for movies, music, retail, books, and social media. They generally work by producing a list of recommendations based on a users interests or past behaviour. Some examples are -\n",
    "\n",
    "- Amazon - providing personalised recommendations based on past orders and products viewed\n",
    "- Google - showing relavent news content based on past searched\n",
    "- Last.fm - offering a station with recommendations based on past listening history and users with similar taste in music\n",
    "\n",
    "Both collaborative filtering and content based filtering was used, content based filtering was based on the information scraped from IMDb. Some of the common problems in recommender systems that were faced are -\n",
    "\n",
    "- Cold start - concerns the issue of a model not being able to make accurate recommendations because it hasn't gathered enough data on a user\n",
    "- Sparsity - concerns the issue of a model not being able to make enough inferences for users or items due to only a small subset of the overall database being rated\n",
    "\n",
    "To test the recommendation system, a function will be defined to allow a user to input their favoutite movie. The output will be a list of recommended movies most simialar to the users input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupLens is a research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specialising in recommender systems, online communities, mobile and ubiquitous technologies, digital libraries, and local geographic information systems.\n",
    "\n",
    "GroupLens Research has collected and made available rating data sets from the [MovieLens web site](http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set.\n",
    "\n",
    "For this project the MovieLens 1M Dataset was used. This is a stable benchmark dataset and contain 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000. The data set was released in February 2003.\n",
    "\n",
    "The dataset was downloaded from the MovieLens [website](http://grouplens.org/datasets/movielens/100k/) and contained three text files in tabular formatting. These are - \n",
    "\n",
    "**movies.dat**\n",
    "\n",
    "The file contains data on 3,883 movies in the format **MovieID::Title::Genres**.\n",
    "\n",
    "\n",
    "|Item    | Description    |\n",
    "|------ | ------|\n",
    "|MovieID    | an integer, ranging from 1 to 3952, that identifies a movie   |\n",
    "|Title    | a String that concatenates movie title and year of release (between brackets)   |\n",
    "|Genres    | a list of genres    |\n",
    "\n",
    "<img src='./Resources/movies.png' width=\"600\">\n",
    "\n",
    "* Titles are identical to titles provided by the IMDB (including year of release)\n",
    "* Genres are pipe-separated and are selected from the following genres: Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western\n",
    "* Some MovieIDs do not correspond to a movie due to accidental duplicate entries and/or test entries\n",
    "* Movies are mostly entered by hand, so errors and inconsistencies may exist\n",
    "\n",
    "\n",
    "**users.dat**\n",
    "\n",
    "The file contains data on 6,040 users in the format **UserID::Gender::Age::Occupation::Zip-code**.\n",
    "\n",
    "\n",
    "|Item    | Description    |\n",
    "|------ | ------|\n",
    "|UserID    | an integer, ranging from 1 to 6040, that identifies a user    |\n",
    "|Gender    | is denoted by a \"M\" for male and \"F\" for female    |\n",
    "|Age    | is an integer identifying a range (the minimum age in the range). Provided ranges are: under 18, 18-24, 25-34, 35-44, 45-49, 50-55, over 56    |\n",
    "|Occupation    | an  integer,  ranging  from  0  to  20,  indicating  the  following  choices:    0:  other  or  not specified, 1: academic/educator, 2: artist, 3: clerical/admin, 4: college/grad student, 5: customer service, 6: doctor/health care, 7: executive/managerial, 8: farmer, 9: homemaker, 10: K-12 student, 11: lawyer, 12: programmer,  13:  retired,  14:  sales/marketing,  15:  scientist,  16:  self-employed,  17:  technician/engineer, 18: tradesman/craftsman, 19: unemployed, 20: writer    |\n",
    "|Age    |  a five-digits integer indicating user ZIP-code    |\n",
    "\n",
    "<img src='./Resources/users.png' width=\"600\">\n",
    "\n",
    "* All demographic information is provided voluntarily by the users and is not checked for accuracy.  Only users who have provided some demographic information are included in this data set.\n",
    "\n",
    "\n",
    "**ratings.dat**\n",
    "\n",
    "The file contains data on 1,000,209 movies in the format **UserID::MovieID::Rating::Timestamp**.\n",
    "\n",
    "\n",
    "|Item    | Description    |\n",
    "|------ | ------|\n",
    "|UserID    | an integer, ranging from 1 to 6040, that identifies a user    |\n",
    "|MovieID    | an integer, ranging from 1 to 3952, that identifies a movie    |\n",
    "|Rating    | an integer, ranging from 1 to 5, made on a 5-star scale (whole-star ratings only)    |\n",
    "|Timestamp    | is represented in seconds since 1/1/1970 UTC     |\n",
    "\n",
    "<img src='./Resources/ratings.png' width=\"600\">\n",
    "\n",
    "* Each user has at least 20 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Movie Database (IMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Internet Movie Database is an online database of movie information. It was launched in 1990 as a hobby project by movie fans and became a subsidary of Amazon Inc in 1998. IMDb collects vast amounts of data on movies and allows registered users to submit new material and edit existing entries. It catalogues all relavent information relating to movies like who starred in it, director, runtime, plot summary, awards, trivia, etc..\n",
    "\n",
    "The OMDb API, a web service to obtain movie information, was used to scrape the relavent data from IMDb. All content and images on the site are contributed and maintained by its users. Please note that the library and its author are not endorsed by or affiliated with OMDbAPI.com.\n",
    "\n",
    "Each OMDb API search method supports the same parameters as the IMDB website and responses are formatted as JSON. The movie information was scraped for each title in **movies.dat**, extracting the title, plot, actors, director, runtime, rating (certificate) and IMDb rating into a new database for further analysis. This was then merged with the rating database and the EDA was performed. The scraped data provided the features for the content based filtering models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baseline was established and it's accuracy was determined using the Root Mean Square Error (RMSE) success metric. All future models were referenced back to the baseline for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering focuses on the similarity between different users (users may give similar ratings to the same items) and the similarity between items (similar movies may be given similar ratings by the users) to make predictions on user-to-item ratings. With collaborative filtering we rarely know the content of features in advance, for this project the data from **ratings.dat** was used.\n",
    "\n",
    "The two catagories of collaborative filtering algorithms looked at were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Memory-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory-based algorithms incorporate the whole user-item database to generate a prediction. They employ statistical techniques to find a set of users that have a history of agreeing with the target user. An example of this is neighbourhood based recommendations and is widely used.\n",
    "\n",
    "Vector cosine based similarity was used to make predictions by taking the weighted average of all the ratings.\n",
    "\n",
    "The main advantages of memory-based algorithms are - \n",
    "\n",
    "- they are easy to implement\n",
    "- new data is easy to add\n",
    "- not dependant on an item's content\n",
    "- scale well with co-rated items\n",
    "\n",
    "It also has its drawbacks - \n",
    "\n",
    "- sparcity\n",
    "- popularity bias\n",
    "\n",
    "And is dependant on users to rate items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model is measured using $\\hat{r}_{xi}^{base} = \\mu + b_{x} + b_{i}$ to estimate the rating by user x for item i.\n",
    "\n",
    "- $\\mu$ = the global mean rating\n",
    "\n",
    "- $b_{x}$ = (the average rating for user x) - $\\mu$\n",
    "\n",
    "- $b_{i}$ = (the average rating fir item i) - $\\mu$  \n",
    "\n",
    "All future models were reference back to this baseline for comparison.\n",
    "\n",
    "The RMSE for the Baseline was **3.39**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Simple cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine distance is a common distance metric in collaborative filtering. The similarity between user/items is measured as the cosine of the angle between two user/item vectors.\n",
    "\n",
    "The cosine similarity ranges from 0 to 1 as there are no negative ratings. The similarity matrices are symmetric and have ones along the diagonal. The cosine distance was determined for both users and items.\n",
    "\n",
    "Predicted rating were calculated using the user and item similatities and accuracy of these predicted ratings were tested against the test dataset.\n",
    "\n",
    "The RMSE for users was **2.73**\n",
    "\n",
    "The RMSE for items was **2.78**\n",
    "\n",
    "These were both improvements upon the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top-k  recommendation algoritm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses cosine distance based similarity models to identify the k closest users (most similar) to an active user. Once the k closest users are found, their corresponding user-item matrices are aggregated to identify the set of items to be recommended.\n",
    "\n",
    "To find the k value with the best accuracy,  I calculated the RMSE over a range of k values.\n",
    "\n",
    "<img src='./Resources/top-k.jpeg' width=\"600\">\n",
    "\n",
    "From the graph it was determined that for item based similarity a k value of 35 produces the lowest RMSE and for user based a k value of 65 produces the lowest RMSE.\n",
    "\n",
    "\n",
    "These values were used to measure the accuracy of the model.\n",
    "\n",
    "The RMSE for users was **2.36**\n",
    "\n",
    "The RMSE for items was **2.34**\n",
    "\n",
    "These were both improvements upon the baseline and the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Simple cosine distance (no bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine distance was used again to determine the similarity between users/items but the Baseline was included to remove any bias on the ratings.\n",
    "\n",
    "The RMSE for users with Baseline was: **2.71**\n",
    "\n",
    "The RMSE for items with Baseline was: **2.72**\n",
    "\n",
    "Both are improvements upon the baseline and the previous model simple cosine distance model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top-k recommendation algoritm (no bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous model the Baseline was addes to the top-k algorithm and the best k value was determined again in case there was a change from the previous model.\n",
    "\n",
    "<img src='./Resources/top-k-bias.jpeg' width=\"600\">\n",
    "\n",
    "From the graph it was determined that for item based similarity the k value was the same but for user based a k value changed to 60.\n",
    "\n",
    "The RMSE for users was **2.4**\n",
    "\n",
    "The RMSE for items was **2.4**\n",
    "\n",
    "While still an improvement in accuracy above the Baseline this model actually performed worse than for the Top-k algorith that included bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model-based algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model based algorithms use different machine learning and data mining methods to predict user rating for unrated items. Bayesian networks, clustering models, single value decomposition (SVD) and latent semantic models are examples examples.\n",
    "\n",
    "The main advantages of model-based algorithms are -\n",
    "\n",
    "- improve prediction performance\n",
    "- better address the sparsity\n",
    "- give an intuitive rationale for recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Single Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular value decomposition (SVD) is a well-known matrix factorization method and collaborative filtering can be formulated by approximating a matrix by using SVD.\n",
    "\n",
    "The winning team of the Netflix Prize competition used [SVD matrix factorization models](http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf) to produce their recommendations.\n",
    "\n",
    "The RMSE for SVD was **2.42**\n",
    "\n",
    "\n",
    "This is an improvement on Baseline but not the most accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based filtering methods incorporate the features of the item and a profile of the user’s preference to create a user-specific content-based profile using discrete attributes. The user’s history of consumption or browsing is used to create a weighted vector of the item features. Weights are learned or assigned to vary the importance of attributes for the particular user.\n",
    "\n",
    "The movie features, scraped from IMDb, were used as the for the models.\n",
    "\n",
    "- Actors\n",
    "- Directors\n",
    "- Genre\n",
    "- Year\n",
    "- Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movie features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-specific content-based profiles were created based on the discrete movie featues - actors, director, year, genre. The features were converted to a binary variable and the history of the user's consumption or browsing was used to create a weighted vector of the item features. \n",
    "\n",
    "Different combinations of features were used to see the differencre in accuracy. These feature combinations were - \n",
    "\n",
    "- actors, directors, genre, year\n",
    "- actors, directors, genre\n",
    "- actors, genre, year\n",
    "- directors, genre, year\n",
    "\n",
    "The cosine similarity was determined for each user-movie pair and predicted rating were calculated. These were tested against the test dataset to determine the model accuracy.\n",
    "\n",
    "\n",
    "The RMSE for feature-based (actors, directors, genre, year) RMSE was **2.803**\n",
    "\n",
    "The RMSE for feature-based (actors, directors, genre) RMSE was **2.8**\n",
    "\n",
    "The RMSE for feature-based (actors, genre, year) RMSE was **2.803**\n",
    "\n",
    "The RMSE for feature-based (directors, genre, year) RMSE was **2.803**\n",
    "\n",
    "\n",
    "The RMSE for the different combinations of features was pretty much identicle but the accuracy was fractionally greater for actors, directors, genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movie plot summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP techniques were used on the movie plot summaries of each movie. TF.IDF scores were used as movie features and if a movie contains a feature, the component for that word is 1 and 0 otherwise.\n",
    "\n",
    "As before, the cosine similarity was determined for each user-movie pair and predicted rating were calculated. These were tested against the test dataset to determine the model accuracy.\n",
    "\n",
    "The RMSE for plot summaries was **2.81**\n",
    "\n",
    "\n",
    "This model performed worse than the previos models for features and is the least accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Collaborative Filtering and Content Based Filtering were used in this project to determine the most accurate model for making movie precictions based on the MovieLens dataset.\n",
    "\n",
    "Model accuracy was measured using RMSE and the aim was to improve the models over the baseline. The Baseline RMSE was found to be ***3.395**.\n",
    "\n",
    "All models and their accuracies are displayed in the graph below.\n",
    "\n",
    "<img src='./Resources/findings.jpeg' width=\"1000\">\n",
    "\n",
    "From the above we can see that there is a clear winner and that overall the best performing models were collaborative filtering based with Item Based Top k coming out aa achieving the best accuracy over the Baseline.\n",
    "\n",
    "\n",
    "Let's look at the performance of each model in the table below.\n",
    "\n",
    "\n",
    "|Model    | RMSE    | % improvement    |\n",
    "|------ | ------|\n",
    "|Baseline    | 3.395   | -    |\n",
    "|Plot CB    | 2.810   | 17.15%    |\n",
    "|Features 4 CB    | 2.8038   | 17.34%    |\n",
    "|Features 3 CB   | 2.8034   | 17.35%    |\n",
    "|Features 1 CB   | 2.8034   | 17.35%    |\n",
    "|Combined CB   | 2.801   | 17.42%    |\n",
    "|Features 2 CB   | 2.8   | 17.45%    |\n",
    "|Item-based CF    | 2.789   | 17.77%    |\n",
    "|User-baser CF    | 2.738   | 19.28%    |\n",
    "|Item-based CF (no bias)   | 2.728   | 19.57%    |\n",
    "|User-baser CF (no bias)   | 2.717   | 19.89%    |\n",
    "|SVD    | 2.423   | 28.56%    |\n",
    "|User-based k=85 (no bias)   | 2.408   | 29%    |\n",
    "|Item-based k=35 (no bias)   | 2.405   | 29.09%    |\n",
    "|User-based k=65    | 2.364   | 30.30%    |\n",
    "|Item-based k=35    | 2.346   | 30.83%    |\n",
    "\n",
    "The model with the lowest accuracy score was the content-based model using the movie plots, it had a RMSE score of **2.810** which was a **17.15%** improvement over the Baseline accuracy. Combining this model with the Content Based model using features increased the accuracy but only fractionally.\n",
    "\n",
    "Collaborative filtering proved the most accurate model with memory based Top k for items. It used the user/movie ratings matrix to determine the cosine similarity between movies. The accuracy was measured over a range of k nearest neighbours and the optimal value of 35 was selected. \n",
    "\n",
    "The Item Based k=35 collaborative filtering model hada  RMSE score of **2.346** which improved on the Baseline by **30.83%**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improve the accuracy of the content based modelling - explore more NLP methods\n",
    "- increase model efficiency\n",
    "- look at additional machine learning techniques - clustering for example could group movies that are related to each other in interesting ways\n",
    "- add more relevant features - sentiment analysis from tweets/IMDb user reviews for example."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
